{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CIFAR10 Transfer Learning based Classifier\n",
    "\n",
    "This notebook outlines the steps to build a classifier to leverage concepts of Transfer Learning by utilizing a pretrained Deep-CNN. \n",
    "Particularly in this case based on VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pandas and Numpy for data structures and util fucntions\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy.random import rand\n",
    "pd.options.display.max_colwidth = 600\n",
    "\n",
    "# Scikit Imports\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import cnn_utils as utils\n",
    "from model_evaluation_utils import get_metrics\n",
    "\n",
    "# Matplot Imports\n",
    "import matplotlib.pyplot as plt\n",
    "params = {'legend.fontsize': 'x-large',\n",
    "          'figure.figsize': (15, 5),\n",
    "          'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "\n",
    "plt.rcParams.update(params)\n",
    "%matplotlib inline\n",
    "\n",
    "# pandas display data frames as tables\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras import callbacks\n",
    "from keras import optimizers\n",
    "from keras.datasets import cifar10\n",
    "from keras.applications import vgg16 as vgg\n",
    "from keras.layers import Dropout, Flatten, Dense, GlobalAveragePooling2D,BatchNormalization\n",
    "from keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 40\n",
    "NUM_CLASSES = 10\n",
    "LEARNING_RATE = 1e-4\n",
    "MOMENTUM = 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.15, \n",
    "                                                  stratify=np.array(y_train), \n",
    "                                                  random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = to_categorical(y_train, NUM_CLASSES)\n",
    "Y_val = to_categorical(y_val, NUM_CLASSES)\n",
    "Y_test = to_categorical(y_test, NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "X_train = np.array([Image.fromarray(x).resize((48,48)) for x in X_train])\n",
    "\n",
    "X_val = np.array([Image.fromarray(x).resize((48,48)) for x in X_val])\n",
    "\n",
    "X_test = np.array([Image.fromarray(x).resize((48,48)) for x in X_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = vgg.VGG16(weights='imagenet', \n",
    "                       include_top=False, \n",
    "                       input_shape=(48, 48, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the last layer from third block of vgg16 model\n",
    "last = base_model.get_layer('block3_pool').output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add classification layers on top of it\n",
    "x = GlobalAveragePooling2D()(last)\n",
    "x= BatchNormalization()(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.6)(x)\n",
    "pred = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "model = keras.Model(base_model.input, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "     layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare data augmentation configuration\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    horizontal_flip=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen.fit(X_train)\n",
    "train_generator = train_datagen.flow(X_train,\n",
    "                                     Y_train, \n",
    "                                     batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1. / 255,\n",
    "    horizontal_flip=False)\n",
    "\n",
    "val_datagen.fit(X_val)\n",
    "val_generator = val_datagen.flow(X_val,\n",
    "                                 Y_val,\n",
    "                                 batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_steps_per_epoch = X_train.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = X_val.shape[0] // BATCH_SIZE\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=train_steps_per_epoch,\n",
    "                    validation_data=val_generator,\n",
    "                    validation_steps=val_steps_per_epoch,\n",
    "                    epochs=EPOCHS,\n",
    "                    verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "t = f.suptitle('Deep Neural Net Performance', fontsize=12)\n",
    "f.subplots_adjust(top=0.85, wspace=0.3)\n",
    "\n",
    "epochs = list(range(1,EPOCHS+1))\n",
    "ax1.plot(epochs, history.history['accuracy'], label='Train Accuracy')\n",
    "ax1.plot(epochs, history.history['val_accuracy'], label='Validation Accuracy')\n",
    "ax1.set_xticks(epochs)\n",
    "ax1.set_ylabel('Accuracy Value')\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_title('Accuracy')\n",
    "l1 = ax1.legend(loc=\"best\")\n",
    "\n",
    "ax2.plot(epochs, history.history['loss'], label='Train Loss')\n",
    "ax2.plot(epochs, history.history['val_loss'], label='Validation Loss')\n",
    "ax2.set_xticks(epochs)\n",
    "ax2.set_ylabel('Loss Value')\n",
    "ax2.set_xlabel('Epoch')\n",
    "ax2.set_title('Loss')\n",
    "l2 = ax2.legend(loc=\"best\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test/255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = list(y_test.squeeze())\n",
    "predictions = list(predictions.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_metrics(true_labels=y_test, \n",
    "                predicted_labels=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = {0:'airplane',\n",
    "             1:'automobile',\n",
    "             2:'bird',\n",
    "             3:'cat',\n",
    "             4:'deer',\n",
    "             5:'dog',\n",
    "             6:'frog',\n",
    "             7:'horse',\n",
    "             8:'ship',\n",
    "             9:'truck'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, 5, figsize=(15, 5))   \n",
    "for i in range(5):\n",
    "    ax[i].imshow(X_test[i])\n",
    "    ax[i].set_title(\"Actual : {}\\nPredicted : {}\".format(label_dict[y_test[i][0]], label_dict[predictions[i]]))\n",
    "    ax[i].axis('off')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A bar plot comparing the accuracy, precision, recall and F1_Score of VGG-16 and three different pre-trained models of your choice from the list:  https://keras.io/api/applications/\n",
    "\n",
    "# VGG-16\n",
    "#train the model on resnet50, vgg16, mobilenet, xception\n",
    "from keras.applications import resnet50, mobilenet\n",
    "\n",
    "# write a loop to train the model on resnet50, vgg16, mobilenet, xception. just change the model name in my code\n",
    "\n",
    "models = ['resnet50', 'mobilenet', 'vgg19']\n",
    "metrics = []\n",
    "for model_name in models:\n",
    "        if model_name == 'vgg19':\n",
    "                base_model = vgg.VGG19(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "                last = base_model.get_layer('block5_pool').output\n",
    "        elif model_name == 'resnet50':\n",
    "                base_model = resnet50.ResNet50(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "                last = base_model.get_layer('conv5_block3_out').output\n",
    "        elif model_name == 'mobilenet':\n",
    "                base_model = mobilenet.MobileNet(weights='imagenet', include_top=False, input_shape=(48, 48, 3))\n",
    "                last = base_model.get_layer('conv_pw_13_relu').output\n",
    "        else:\n",
    "                print('Model not found')\n",
    "                break\n",
    "\n",
    "        # Add classification layers on top of it\n",
    "        x = GlobalAveragePooling2D()(last)\n",
    "        x= BatchNormalization()(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dense(256, activation='relu')(x)\n",
    "        x = Dropout(0.6)(x)\n",
    "        pred = Dense(NUM_CLASSES, activation='softmax')(x)\n",
    "        model = keras.Model(base_model.input, pred)\n",
    "\n",
    "        for layer in base_model.layers:\n",
    "                layer.trainable = False\n",
    "\n",
    "        model.compile(loss='binary_crossentropy',\n",
    "                            optimizer=optimizers.Adam(learning_rate=LEARNING_RATE),\n",
    "                            metrics=['accuracy'])\n",
    "        \n",
    "        model.summary()\n",
    "\n",
    "        history = model.fit(train_generator,\n",
    "                                steps_per_epoch=train_steps_per_epoch,\n",
    "                                validation_data=val_generator,\n",
    "                                validation_steps=val_steps_per_epoch,\n",
    "                                epochs=EPOCHS,\n",
    "                                verbose=1)\n",
    "\n",
    "        predictions = model.predict(X_test/255.)\n",
    "\n",
    "        test_labels = list(y_test.squeeze())\n",
    "\n",
    "        predictions = list(predictions.argmax(axis=1))\n",
    "\n",
    "\n",
    "        #save the metrics in a list\n",
    "        metrics.append(get_metrics(true_labels=y_test, \n",
    "                predicted_labels=predictions))\n",
    "        \n",
    "\n",
    "#plot the metrics\n",
    "        \n",
    "metrics_df = pd.DataFrame(metrics, index=models)\n",
    "metrics_df.plot(kind='bar', figsize=(15, 5))\n",
    "plt.title('Performance Comparison')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
